# Machine-Learning
Implementation of various Machine Learning, Deep Learning methods. Some of the algorithms are coded from scratch, some are based on available libraries.

<br /> 0 - Dimensionality Reduction Methods
<br /> Comparison between PCA, CCA, KPCA, t-SNE & ISOMAP.

<br /> 1 - Regression methods (implemented from scratch)
<br /> A. Linear Regression to predict House Prices.
<br /> B. Logsitic Regression (Stochastic Gradient Descent) to predict Employement.
  


<br /> 2 - Deep Learning
<br /> A. Implement Deep Neural Nets (TensorFlow) with RELU activation units to classify MNIST data.
<br /> B. Convolutional Neural Nets (TensorFlow) to classify FASHION MNIST data.
<br /> C. ARIMA vs. LSTM (Keras) for BitCoin Price prediciton.
<br /> C. Deep Ladder Nets (Neural Nets modelled in TensorFlow) to classify MNIST data, given only 1% of the data is labelled. Inspired by https://github.com/CuriousAI/ladder



<br /> 3 - Twitter Language Model
<br /> Predict Language using a Character Level Unigram Markov Model.

<br /> 4 - Decision Trees
<br /> A. AdaBoost: Implementation of algorithm from scratch to predict probability of Breast Cancer.
<br /> B. CART: Implementation of algorithm from scratch on IRIS dataset.

<br /> 5 - Ensemble Learning
<br /> Prediciton of Survival on TITANIC dataset. The final prediciton was generated using an ensemble of Random Forest, GradBoost, SVM, LogReg, AdaBoost learners that were finally passed through XGBoost.

<br /> 6 - Expectation Maximization

<br /> 7 - Generative Adverserial Network:
<br /> Implementation of a GAN with fully-connected layers for both Generator and Discriminator to learn a multimodal distribution. The loss used for training was Wasserstein Loss. Inspired by https://github.com/igul222/improved_wgan_training

